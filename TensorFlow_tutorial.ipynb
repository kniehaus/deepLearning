{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Flow Introduction\n",
    "November 2016, KN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import more modules\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "Going through simple tutorial first, just to go through https://www.tensorflow.org/versions/r0.11/tutorials/mnist/beginners/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Load up MNIST data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of training set: (55000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x11fd78890>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0AEgEwQ6AGTi/wHBex1yuR8aAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120b2e710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Illustrate raw data\n",
    "print('Dimensions of training set: {0}'.format(np.shape(mnist.train.images)))\n",
    "exInd = 5\n",
    "exImage = mnist.train.images[exInd,:].reshape(28,-1)  # 28x28 pixels in each image\n",
    "plt.pcolormesh(exImage, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set-up tensor flow variables\n",
    "dimen = 28*28  # Size of images and therefore the imput vectors\n",
    "numClasses = 10   # Number of possible digits (0-9)\n",
    "\n",
    "# Placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, dimen])\n",
    "# None means dimension can be of any length\n",
    "# Doing this to create placeholder for each 28x28 pixel image\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, numClasses])\n",
    "# one-hot vector indivating true digit class\n",
    "\n",
    "# Variables\n",
    "# (model parameters are usually tensorflow variables)\n",
    "# Need to initialize values for variables\n",
    "w = tf.Variable(tf.zeros([dimen,numClasses]))\n",
    "b = tf.Variable(tf.zeros([numClasses]))\n",
    "\n",
    "# Softmax\n",
    "y = tf.nn.softmax(tf.matmul(x,w) + b)\n",
    "\n",
    "# Cross-entropy\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_true*tf.log(y), reduction_indices=[1]))\n",
    "# tf.reduce_mean gets mean cross-entropy for all samples\n",
    "# more numerically stable:\n",
    "#cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_true))\n",
    "# but then softmax already taken, so would remove from y function \n",
    "\n",
    "# Need to initialize variables and launch a session\n",
    "# Session is connection to C++ code backend to do computation\n",
    "# First, create graph and then launch in a session\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimize\n",
    "learnRate = 0.5\n",
    "train_step = tf.train.GradientDescentOptimizer(learnRate).minimize(cross_entropy)\n",
    "# When this step is run, it will apply gradient descent updates to params\n",
    "\n",
    "# Running training step\n",
    "numSteps = 1000\n",
    "batchSize = 100\n",
    "for i in range(numSteps):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batchSize)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_true: batch_ys})\n",
    "    # feed_dict replaces placeholders with training examples\n",
    "    # (can use feed_dict to replace any tensor in computation graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at performance in training data\n",
    "predLabels = tf.argmax(y,1)\n",
    "trueLabels = tf.argmax(y_true,1)\n",
    "\n",
    "ifCorrect = tf.equal(predLabels, trueLabels)\n",
    "\n",
    "accFunc = tf.reduce_mean(tf.cast(ifCorrect, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 91.81%\n"
     ]
    }
   ],
   "source": [
    "# Look at performance in test data\n",
    "\n",
    "testPerf_acc = sess.run(accFunc, feed_dict={x:mnist.test.images, y_true:mnist.test.labels})\n",
    "print('Test accuracy: {0:.2f}%'.format(100*testPerf_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With interactive session\n",
    "\n",
    "https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 91.95%\n"
     ]
    }
   ],
   "source": [
    "# Or, can use an interactive session\n",
    "# With interactive session, can interleave graph-building and graph-running operations\n",
    "sess2 = tf.InteractiveSession()\n",
    "\n",
    "# (As above)\n",
    "dimen = 28*28  # Size of images and therefore the imput vectors\n",
    "numClasses = 10   # Number of possible digits (0-9)\n",
    "# Placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, dimen])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, numClasses])\n",
    "# Variables\n",
    "w = tf.Variable(tf.zeros([dimen,numClasses]))\n",
    "b = tf.Variable(tf.zeros([numClasses]))\n",
    "# Regression model\n",
    "y = tf.matmul(x,w) + b\n",
    "# Cross-entropy\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))\n",
    "\n",
    "sess2.run(tf.initialize_all_variables())\n",
    "\n",
    "# Optimize\n",
    "learnRate = 0.5\n",
    "train_step = tf.train.GradientDescentOptimizer(learnRate).minimize(cross_entropy)\n",
    "\n",
    "# Running training step\n",
    "numSteps = 1000\n",
    "batchSize = 100\n",
    "for i in range(numSteps):\n",
    "    batch = mnist.train.next_batch(batchSize)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "    \n",
    "# Look at performance\n",
    "predLabels = tf.argmax(y,1)\n",
    "trueLabels = tf.argmax(y_,1)\n",
    "\n",
    "ifCorrect = tf.equal(predLabels, trueLabels)\n",
    "accFunc = tf.reduce_mean(tf.cast(ifCorrect, tf.float32))\n",
    "\n",
    "testPerf_acc = accFunc.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "print('Test accuracy: {0:.2f}%'.format(100*testPerf_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simply conv net\n",
    "\n",
    "https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/index.html\n",
    "\n",
    "Remember: CNN is a bunch of convolution layers + ReLU applied\n",
    "(where the filters [= conv layers = kernels = filters = feature detectors] are learned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make some functions \n",
    "\n",
    "def weight_variable(shape):\n",
    "    \"\"\"Want weight initializations to have noise for symmetry breaking\"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"Want positive bias for ReLU neurons to avoid dead neurons (i.e., never activate)\"\"\"\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    \"\"\"Want to set stride and keep zero padding\n",
    "    \n",
    "    Zero padding: means that when applying convolution at edges, pad with zeros \n",
    "    to enable the computation (vs. narrow convolution)\n",
    "    \n",
    "    Stride size: amount to shift filter in each step\n",
    "    \"\"\"\n",
    "    return tf.nn.conv2d(x,W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    \"\"\"Want to do max pooling over 2x2 blocks\"\"\"\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set variables\n",
    "patchSize = [5,5]\n",
    "numInputChannels = 1  # (number color channels)\n",
    "numOutputChannels = 32\n",
    "dim1side = 28\n",
    "\n",
    "# Create first convolutional layer\n",
    "W_conv1 = weight_variable([patchSize[0], patchSize[1], numInputChannels, numOutputChannels])\n",
    "b_conv1 = bias_variable([numOutputChannels])\n",
    "\n",
    "# reshape images into 4d tensor of: [numExamples, width, height, num color channels]\n",
    "x_image = tf.reshape(x, [-1, dim1side, dim1side,numInputChannels])\n",
    "\n",
    "# convolve image with weight tensor and add bias\n",
    "conv1 = conv2d(x_image, W_conv1) + b_conv1\n",
    "# apply ReLU function\n",
    "h_conv1 = tf.nn.relu(conv1)\n",
    "# max pool\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16, 13],\n",
       "       [12, 11]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [[3,2], [1,4]]\n",
    "B = [[4,3],[2,2]]\n",
    "\n",
    "np.dot(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
